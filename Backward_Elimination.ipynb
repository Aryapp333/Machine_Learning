{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTKL0yxF2Qnq"
      },
      "source": [
        "\n",
        "\n",
        "Backward Elimination\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jK2xc4CD22Ay"
      },
      "outputs": [],
      "source": [
        "# 1.importing libraries\n",
        "\n",
        "import numpy as nm\n",
        "import matplotlib.pyplot as mtp\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ91BKOL3JjJ",
        "outputId": "9718fc10-5fb4-48bf-9377-bf5005d6ce63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
            "0   165349.20       136897.80        471784.10    New York  192261.83\n",
            "1   162597.70       151377.59        443898.53  California  191792.06\n",
            "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
            "3   144372.41       118671.85        383199.62    New York  182901.99\n",
            "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
            "5   131876.90        99814.71        362861.36    New York  156991.12\n",
            "6   134615.46       147198.87        127716.82  California  156122.51\n",
            "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
            "8   120542.52       148718.95        311613.29    New York  152211.77\n",
            "9   123334.88       108679.17        304981.62  California  149759.96\n",
            "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
            "11  100671.96        91790.61        249744.55  California  144259.40\n",
            "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
            "13   91992.39       135495.07        252664.93  California  134307.35\n",
            "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
            "15  114523.61       122616.84        261776.23    New York  129917.04\n",
            "16   78013.11       121597.55        264346.06  California  126992.93\n",
            "17   94657.16       145077.58        282574.31    New York  125370.37\n",
            "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
            "19   86419.70       153514.11             0.00    New York  122776.86\n",
            "20   76253.86       113867.30        298664.47  California  118474.03\n",
            "21   78389.47       153773.43        299737.29    New York  111313.02\n",
            "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
            "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
            "24   77044.01        99281.34        140574.81    New York  108552.04\n",
            "25   64664.71       139553.16        137962.62  California  107404.34\n",
            "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
            "27   72107.60       127864.55        353183.81    New York  105008.31\n",
            "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
            "29   65605.48       153032.06        107138.38    New York  101004.64\n",
            "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
            "31   61136.38       152701.92         88218.23    New York   97483.56\n",
            "32   63408.86       129219.61         46085.25  California   97427.84\n",
            "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
            "34   46426.07       157693.92        210797.67  California   96712.80\n",
            "35   46014.02        85047.44        205517.64    New York   96479.51\n",
            "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
            "37   44069.95        51283.14        197029.42  California   89949.14\n",
            "38   20229.59        65947.93        185265.10    New York   81229.06\n",
            "39   38558.51        82982.09        174999.30  California   81005.76\n",
            "40   28754.33       118546.05        172795.67  California   78239.91\n",
            "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
            "42   23640.93        96189.63        148001.11  California   71498.49\n",
            "43   15505.73       127382.30         35534.17    New York   69758.98\n",
            "44   22177.74       154806.14         28334.72  California   65200.33\n",
            "45    1000.23       124153.04          1903.93    New York   64926.08\n",
            "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
            "47       0.00       135426.92             0.00  California   42559.73\n",
            "48     542.05        51743.15             0.00    New York   35673.41\n",
            "49       0.00       116983.80         45173.06  California   14681.40\n"
          ]
        }
      ],
      "source": [
        "# 2.importing datasets\n",
        "\n",
        "data_set = pd.read_csv('/content/50_CompList.csv')\n",
        "print(data_set.to_string())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vaTCbBMQ3UgZ"
      },
      "outputs": [],
      "source": [
        "# 3.Extracting Independent and dependent Variable\n",
        "\n",
        "x = data_set.iloc[:, :-1].values\n",
        "y = data_set.iloc[:, 4].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtDAp3sm365Z",
        "outputId": "bb756a36-4678-45fc-bcdf-fa09c573b9ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X Data\n",
            "            0          1          2           3\n",
            "0    165349.2   136897.8   471784.1    New York\n",
            "1    162597.7  151377.59  443898.53  California\n",
            "2   153441.51  101145.55  407934.54     Florida\n",
            "3   144372.41  118671.85  383199.62    New York\n",
            "4   142107.34   91391.77  366168.42     Florida\n",
            "5    131876.9   99814.71  362861.36    New York\n",
            "6   134615.46  147198.87  127716.82  California\n",
            "7   130298.13  145530.06  323876.68     Florida\n",
            "8   120542.52  148718.95  311613.29    New York\n",
            "9   123334.88  108679.17  304981.62  California\n",
            "10  101913.08  110594.11  229160.95     Florida\n",
            "11  100671.96   91790.61  249744.55  California\n",
            "12   93863.75  127320.38  249839.44     Florida\n",
            "13   91992.39  135495.07  252664.93  California\n",
            "14  119943.24  156547.42  256512.92     Florida\n",
            "15  114523.61  122616.84  261776.23    New York\n",
            "16   78013.11  121597.55  264346.06  California\n",
            "17   94657.16  145077.58  282574.31    New York\n",
            "18   91749.16  114175.79  294919.57     Florida\n",
            "19    86419.7  153514.11        0.0    New York\n",
            "20   76253.86   113867.3  298664.47  California\n",
            "21   78389.47  153773.43  299737.29    New York\n",
            "22   73994.56  122782.75  303319.26     Florida\n",
            "23   67532.53  105751.03  304768.73     Florida\n",
            "24   77044.01   99281.34  140574.81    New York\n",
            "25   64664.71  139553.16  137962.62  California\n",
            "26   75328.87  144135.98  134050.07     Florida\n",
            "27    72107.6  127864.55  353183.81    New York\n",
            "28   66051.52  182645.56   118148.2     Florida\n",
            "29   65605.48  153032.06  107138.38    New York\n",
            "30   61994.48  115641.28   91131.24     Florida\n",
            "31   61136.38  152701.92   88218.23    New York\n",
            "32   63408.86  129219.61   46085.25  California\n",
            "33   55493.95  103057.49  214634.81     Florida\n",
            "34   46426.07  157693.92  210797.67  California\n",
            "35   46014.02   85047.44  205517.64    New York\n",
            "36   28663.76  127056.21  201126.82     Florida\n",
            "37   44069.95   51283.14  197029.42  California\n",
            "38   20229.59   65947.93   185265.1    New York\n",
            "39   38558.51   82982.09   174999.3  California\n",
            "40   28754.33  118546.05  172795.67  California\n",
            "41   27892.92   84710.77  164470.71     Florida\n",
            "42   23640.93   96189.63  148001.11  California\n",
            "43   15505.73   127382.3   35534.17    New York\n",
            "44   22177.74  154806.14   28334.72  California\n",
            "45    1000.23  124153.04    1903.93    New York\n",
            "46    1315.46  115816.21  297114.46     Florida\n",
            "47        0.0  135426.92        0.0  California\n",
            "48     542.05   51743.15        0.0    New York\n",
            "49        0.0   116983.8   45173.06  California\n",
            "Y Data\n",
            "            0\n",
            "0   192261.83\n",
            "1   191792.06\n",
            "2   191050.39\n",
            "3   182901.99\n",
            "4   166187.94\n",
            "5   156991.12\n",
            "6   156122.51\n",
            "7   155752.60\n",
            "8   152211.77\n",
            "9   149759.96\n",
            "10  146121.95\n",
            "11  144259.40\n",
            "12  141585.52\n",
            "13  134307.35\n",
            "14  132602.65\n",
            "15  129917.04\n",
            "16  126992.93\n",
            "17  125370.37\n",
            "18  124266.90\n",
            "19  122776.86\n",
            "20  118474.03\n",
            "21  111313.02\n",
            "22  110352.25\n",
            "23  108733.99\n",
            "24  108552.04\n",
            "25  107404.34\n",
            "26  105733.54\n",
            "27  105008.31\n",
            "28  103282.38\n",
            "29  101004.64\n",
            "30   99937.59\n",
            "31   97483.56\n",
            "32   97427.84\n",
            "33   96778.92\n",
            "34   96712.80\n",
            "35   96479.51\n",
            "36   90708.19\n",
            "37   89949.14\n",
            "38   81229.06\n",
            "39   81005.76\n",
            "40   78239.91\n",
            "41   77798.83\n",
            "42   71498.49\n",
            "43   69758.98\n",
            "44   65200.33\n",
            "45   64926.08\n",
            "46   49490.75\n",
            "47   42559.73\n",
            "48   35673.41\n",
            "49   14681.40\n"
          ]
        }
      ],
      "source": [
        "# 4.display x and y\n",
        "\n",
        "df1=pd.DataFrame(x)\n",
        "print(\"X Data\")\n",
        "print(df1.to_string())\n",
        "df2=pd.DataFrame(y)\n",
        "print(\"Y Data\")\n",
        "print(df2.to_string())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BpwlBKbmvhhx"
      },
      "outputs": [],
      "source": [
        "# 5.Catgorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "labelencoder_x= LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VC5tDYYvtDJ",
        "outputId": "4d95795d-c1b6-4272-dc48-cb340eb53e03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            0          1          2  3\n",
            "0    165349.2   136897.8   471784.1  2\n",
            "1    162597.7  151377.59  443898.53  0\n",
            "2   153441.51  101145.55  407934.54  1\n",
            "3   144372.41  118671.85  383199.62  2\n",
            "4   142107.34   91391.77  366168.42  1\n",
            "5    131876.9   99814.71  362861.36  2\n",
            "6   134615.46  147198.87  127716.82  0\n",
            "7   130298.13  145530.06  323876.68  1\n",
            "8   120542.52  148718.95  311613.29  2\n",
            "9   123334.88  108679.17  304981.62  0\n",
            "10  101913.08  110594.11  229160.95  1\n",
            "11  100671.96   91790.61  249744.55  0\n",
            "12   93863.75  127320.38  249839.44  1\n",
            "13   91992.39  135495.07  252664.93  0\n",
            "14  119943.24  156547.42  256512.92  1\n",
            "15  114523.61  122616.84  261776.23  2\n",
            "16   78013.11  121597.55  264346.06  0\n",
            "17   94657.16  145077.58  282574.31  2\n",
            "18   91749.16  114175.79  294919.57  1\n",
            "19    86419.7  153514.11        0.0  2\n",
            "20   76253.86   113867.3  298664.47  0\n",
            "21   78389.47  153773.43  299737.29  2\n",
            "22   73994.56  122782.75  303319.26  1\n",
            "23   67532.53  105751.03  304768.73  1\n",
            "24   77044.01   99281.34  140574.81  2\n",
            "25   64664.71  139553.16  137962.62  0\n",
            "26   75328.87  144135.98  134050.07  1\n",
            "27    72107.6  127864.55  353183.81  2\n",
            "28   66051.52  182645.56   118148.2  1\n",
            "29   65605.48  153032.06  107138.38  2\n",
            "30   61994.48  115641.28   91131.24  1\n",
            "31   61136.38  152701.92   88218.23  2\n",
            "32   63408.86  129219.61   46085.25  0\n",
            "33   55493.95  103057.49  214634.81  1\n",
            "34   46426.07  157693.92  210797.67  0\n",
            "35   46014.02   85047.44  205517.64  2\n",
            "36   28663.76  127056.21  201126.82  1\n",
            "37   44069.95   51283.14  197029.42  0\n",
            "38   20229.59   65947.93   185265.1  2\n",
            "39   38558.51   82982.09   174999.3  0\n",
            "40   28754.33  118546.05  172795.67  0\n",
            "41   27892.92   84710.77  164470.71  1\n",
            "42   23640.93   96189.63  148001.11  0\n",
            "43   15505.73   127382.3   35534.17  2\n",
            "44   22177.74  154806.14   28334.72  0\n",
            "45    1000.23  124153.04    1903.93  2\n",
            "46    1315.46  115816.21  297114.46  1\n",
            "47        0.0  135426.92        0.0  0\n",
            "48     542.05   51743.15        0.0  2\n",
            "49        0.0   116983.8   45173.06  0\n"
          ]
        }
      ],
      "source": [
        "# 6.transforming to 0,1 and 2\n",
        "x[:, 3] = labelencoder_x.fit_transform(x[:, 3])\n",
        "df2=pd.DataFrame(x)\n",
        "print(df2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x648Fsy_v6Nw",
        "outputId": "8d139b4f-4187-4c2b-f176-592a31b6c195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      0    1    2          3          4          5\n",
            "0   0.0  0.0  1.0   165349.2   136897.8   471784.1\n",
            "1   1.0  0.0  0.0   162597.7  151377.59  443898.53\n",
            "2   0.0  1.0  0.0  153441.51  101145.55  407934.54\n",
            "3   0.0  0.0  1.0  144372.41  118671.85  383199.62\n",
            "4   0.0  1.0  0.0  142107.34   91391.77  366168.42\n",
            "5   0.0  0.0  1.0   131876.9   99814.71  362861.36\n",
            "6   1.0  0.0  0.0  134615.46  147198.87  127716.82\n",
            "7   0.0  1.0  0.0  130298.13  145530.06  323876.68\n",
            "8   0.0  0.0  1.0  120542.52  148718.95  311613.29\n",
            "9   1.0  0.0  0.0  123334.88  108679.17  304981.62\n",
            "10  0.0  1.0  0.0  101913.08  110594.11  229160.95\n",
            "11  1.0  0.0  0.0  100671.96   91790.61  249744.55\n",
            "12  0.0  1.0  0.0   93863.75  127320.38  249839.44\n",
            "13  1.0  0.0  0.0   91992.39  135495.07  252664.93\n",
            "14  0.0  1.0  0.0  119943.24  156547.42  256512.92\n",
            "15  0.0  0.0  1.0  114523.61  122616.84  261776.23\n",
            "16  1.0  0.0  0.0   78013.11  121597.55  264346.06\n",
            "17  0.0  0.0  1.0   94657.16  145077.58  282574.31\n",
            "18  0.0  1.0  0.0   91749.16  114175.79  294919.57\n",
            "19  0.0  0.0  1.0    86419.7  153514.11        0.0\n",
            "20  1.0  0.0  0.0   76253.86   113867.3  298664.47\n",
            "21  0.0  0.0  1.0   78389.47  153773.43  299737.29\n",
            "22  0.0  1.0  0.0   73994.56  122782.75  303319.26\n",
            "23  0.0  1.0  0.0   67532.53  105751.03  304768.73\n",
            "24  0.0  0.0  1.0   77044.01   99281.34  140574.81\n",
            "25  1.0  0.0  0.0   64664.71  139553.16  137962.62\n",
            "26  0.0  1.0  0.0   75328.87  144135.98  134050.07\n",
            "27  0.0  0.0  1.0    72107.6  127864.55  353183.81\n",
            "28  0.0  1.0  0.0   66051.52  182645.56   118148.2\n",
            "29  0.0  0.0  1.0   65605.48  153032.06  107138.38\n",
            "30  0.0  1.0  0.0   61994.48  115641.28   91131.24\n",
            "31  0.0  0.0  1.0   61136.38  152701.92   88218.23\n",
            "32  1.0  0.0  0.0   63408.86  129219.61   46085.25\n",
            "33  0.0  1.0  0.0   55493.95  103057.49  214634.81\n",
            "34  1.0  0.0  0.0   46426.07  157693.92  210797.67\n",
            "35  0.0  0.0  1.0   46014.02   85047.44  205517.64\n",
            "36  0.0  1.0  0.0   28663.76  127056.21  201126.82\n",
            "37  1.0  0.0  0.0   44069.95   51283.14  197029.42\n",
            "38  0.0  0.0  1.0   20229.59   65947.93   185265.1\n",
            "39  1.0  0.0  0.0   38558.51   82982.09   174999.3\n",
            "40  1.0  0.0  0.0   28754.33  118546.05  172795.67\n",
            "41  0.0  1.0  0.0   27892.92   84710.77  164470.71\n",
            "42  1.0  0.0  0.0   23640.93   96189.63  148001.11\n",
            "43  0.0  0.0  1.0   15505.73   127382.3   35534.17\n",
            "44  1.0  0.0  0.0   22177.74  154806.14   28334.72\n",
            "45  0.0  0.0  1.0    1000.23  124153.04    1903.93\n",
            "46  0.0  1.0  0.0    1315.46  115816.21  297114.46\n",
            "47  1.0  0.0  0.0        0.0  135426.92        0.0\n",
            "48  0.0  0.0  1.0     542.05   51743.15        0.0\n",
            "49  1.0  0.0  0.0        0.0   116983.8   45173.06\n"
          ]
        }
      ],
      "source": [
        "# 7.State column ,Transforming\n",
        "ct = ColumnTransformer([(\"State\", OneHotEncoder(), [3])], remainder = 'passthrough')\n",
        "x = ct.fit_transform(x)\n",
        "#Transformed State column\n",
        "df4=pd.DataFrame(x)\n",
        "print(df4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs3Rk76QwAG4",
        "outputId": "c3f46e96-a899-44ae-f889-098c0b14e5a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X\n",
            "[[0.0 1.0 165349.2 136897.8 471784.1]\n",
            " [0.0 0.0 162597.7 151377.59 443898.53]\n",
            " [1.0 0.0 153441.51 101145.55 407934.54]\n",
            " [0.0 1.0 144372.41 118671.85 383199.62]\n",
            " [1.0 0.0 142107.34 91391.77 366168.42]\n",
            " [0.0 1.0 131876.9 99814.71 362861.36]\n",
            " [0.0 0.0 134615.46 147198.87 127716.82]\n",
            " [1.0 0.0 130298.13 145530.06 323876.68]\n",
            " [0.0 1.0 120542.52 148718.95 311613.29]\n",
            " [0.0 0.0 123334.88 108679.17 304981.62]\n",
            " [1.0 0.0 101913.08 110594.11 229160.95]\n",
            " [0.0 0.0 100671.96 91790.61 249744.55]\n",
            " [1.0 0.0 93863.75 127320.38 249839.44]\n",
            " [0.0 0.0 91992.39 135495.07 252664.93]\n",
            " [1.0 0.0 119943.24 156547.42 256512.92]\n",
            " [0.0 1.0 114523.61 122616.84 261776.23]\n",
            " [0.0 0.0 78013.11 121597.55 264346.06]\n",
            " [0.0 1.0 94657.16 145077.58 282574.31]\n",
            " [1.0 0.0 91749.16 114175.79 294919.57]\n",
            " [0.0 1.0 86419.7 153514.11 0.0]\n",
            " [0.0 0.0 76253.86 113867.3 298664.47]\n",
            " [0.0 1.0 78389.47 153773.43 299737.29]\n",
            " [1.0 0.0 73994.56 122782.75 303319.26]\n",
            " [1.0 0.0 67532.53 105751.03 304768.73]\n",
            " [0.0 1.0 77044.01 99281.34 140574.81]\n",
            " [0.0 0.0 64664.71 139553.16 137962.62]\n",
            " [1.0 0.0 75328.87 144135.98 134050.07]\n",
            " [0.0 1.0 72107.6 127864.55 353183.81]\n",
            " [1.0 0.0 66051.52 182645.56 118148.2]\n",
            " [0.0 1.0 65605.48 153032.06 107138.38]\n",
            " [1.0 0.0 61994.48 115641.28 91131.24]\n",
            " [0.0 1.0 61136.38 152701.92 88218.23]\n",
            " [0.0 0.0 63408.86 129219.61 46085.25]\n",
            " [1.0 0.0 55493.95 103057.49 214634.81]\n",
            " [0.0 0.0 46426.07 157693.92 210797.67]\n",
            " [0.0 1.0 46014.02 85047.44 205517.64]\n",
            " [1.0 0.0 28663.76 127056.21 201126.82]\n",
            " [0.0 0.0 44069.95 51283.14 197029.42]\n",
            " [0.0 1.0 20229.59 65947.93 185265.1]\n",
            " [0.0 0.0 38558.51 82982.09 174999.3]\n",
            " [0.0 0.0 28754.33 118546.05 172795.67]\n",
            " [1.0 0.0 27892.92 84710.77 164470.71]\n",
            " [0.0 0.0 23640.93 96189.63 148001.11]\n",
            " [0.0 1.0 15505.73 127382.3 35534.17]\n",
            " [0.0 0.0 22177.74 154806.14 28334.72]\n",
            " [0.0 1.0 1000.23 124153.04 1903.93]\n",
            " [1.0 0.0 1315.46 115816.21 297114.46]\n",
            " [0.0 0.0 0.0 135426.92 0.0]\n",
            " [0.0 1.0 542.05 51743.15 0.0]\n",
            " [0.0 0.0 0.0 116983.8 45173.06]]\n"
          ]
        }
      ],
      "source": [
        "# 8.Avoiding the dummy variable trap:\n",
        "x = x[:, 1:]\n",
        "print(\"X\")\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtZha5Q4wOcj",
        "outputId": "90c98ab4-b26b-417c-b599-0eb82e26a8f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      0          1          2          3\n",
            "0   1.0   165349.2   136897.8   471784.1\n",
            "1   0.0   162597.7  151377.59  443898.53\n",
            "2   0.0  153441.51  101145.55  407934.54\n",
            "3   1.0  144372.41  118671.85  383199.62\n",
            "4   0.0  142107.34   91391.77  366168.42\n",
            "5   1.0   131876.9   99814.71  362861.36\n",
            "6   0.0  134615.46  147198.87  127716.82\n",
            "7   0.0  130298.13  145530.06  323876.68\n",
            "8   1.0  120542.52  148718.95  311613.29\n",
            "9   0.0  123334.88  108679.17  304981.62\n",
            "10  0.0  101913.08  110594.11  229160.95\n",
            "11  0.0  100671.96   91790.61  249744.55\n",
            "12  0.0   93863.75  127320.38  249839.44\n",
            "13  0.0   91992.39  135495.07  252664.93\n",
            "14  0.0  119943.24  156547.42  256512.92\n",
            "15  1.0  114523.61  122616.84  261776.23\n",
            "16  0.0   78013.11  121597.55  264346.06\n",
            "17  1.0   94657.16  145077.58  282574.31\n",
            "18  0.0   91749.16  114175.79  294919.57\n",
            "19  1.0    86419.7  153514.11        0.0\n",
            "20  0.0   76253.86   113867.3  298664.47\n",
            "21  1.0   78389.47  153773.43  299737.29\n",
            "22  0.0   73994.56  122782.75  303319.26\n",
            "23  0.0   67532.53  105751.03  304768.73\n",
            "24  1.0   77044.01   99281.34  140574.81\n",
            "25  0.0   64664.71  139553.16  137962.62\n",
            "26  0.0   75328.87  144135.98  134050.07\n",
            "27  1.0    72107.6  127864.55  353183.81\n",
            "28  0.0   66051.52  182645.56   118148.2\n",
            "29  1.0   65605.48  153032.06  107138.38\n",
            "30  0.0   61994.48  115641.28   91131.24\n",
            "31  1.0   61136.38  152701.92   88218.23\n",
            "32  0.0   63408.86  129219.61   46085.25\n",
            "33  0.0   55493.95  103057.49  214634.81\n",
            "34  0.0   46426.07  157693.92  210797.67\n",
            "35  1.0   46014.02   85047.44  205517.64\n",
            "36  0.0   28663.76  127056.21  201126.82\n",
            "37  0.0   44069.95   51283.14  197029.42\n",
            "38  1.0   20229.59   65947.93   185265.1\n",
            "39  0.0   38558.51   82982.09   174999.3\n",
            "40  0.0   28754.33  118546.05  172795.67\n",
            "41  0.0   27892.92   84710.77  164470.71\n",
            "42  0.0   23640.93   96189.63  148001.11\n",
            "43  1.0   15505.73   127382.3   35534.17\n",
            "44  0.0   22177.74  154806.14   28334.72\n",
            "45  1.0    1000.23  124153.04    1903.93\n",
            "46  0.0    1315.46  115816.21  297114.46\n",
            "47  0.0        0.0  135426.92        0.0\n",
            "48  1.0     542.05   51743.15        0.0\n",
            "49  0.0        0.0   116983.8   45173.06\n"
          ]
        }
      ],
      "source": [
        "# 9.With out dummy\n",
        "df5=pd.DataFrame(x)\n",
        "print(df5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bllTTW1uwWBT"
      },
      "outputs": [],
      "source": [
        "# 10.Splitting the dataset into training and test set.\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "rK9--fv1wa_b",
        "outputId": "e116e4df-ed12-4c6f-a5a6-910f495bc349"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 11.Fitting the MLR model to the training set:\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(x_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oyJgH7WYwfgg"
      },
      "outputs": [],
      "source": [
        "# 12.Predicting the Test set result;\n",
        "y_pred = regressor.predict(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99GjPJGnwjjC",
        "outputId": "ca821fab-2df5-4534-ef12-1138b7054b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Score:  95.01020786438474 %\n",
            "Test Score:  93.67033175940503 %\n"
          ]
        }
      ],
      "source": [
        "# 13.Checking the score\n",
        "print('Train Score: ', regressor.score(x_train, y_train)*100,\"%\")\n",
        "print('Test Score: ', regressor.score(x_test, y_test)*100,\"%\")\n",
        "pre=[[1.0,0.0,165385.5,136222.6]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N_QkyxVwrj4",
        "outputId": "cfbc3d36-336c-410c-aa10-56f635b8c254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[53595.36616693]\n"
          ]
        }
      ],
      "source": [
        "# 14.Predicting the  result of 'pre'\n",
        "pred = regressor.predict(pre)\n",
        "\n",
        "print(pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

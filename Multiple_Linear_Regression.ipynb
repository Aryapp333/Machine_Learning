{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Linear Regression\n"
      ],
      "metadata": {
        "id": "MHvSjEg_Zzzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.importing libraries\n",
        "import numpy as nm\n",
        "import matplotlib.pyplot as mtp\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gz9U8KAvaFlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.importing dataset\n",
        "data_set= pd.read_csv('/content/50_CompList.csv')\n",
        "print(data_set.to_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFXukpDDbe5s",
        "outputId": "fc4fd1d9-3f14-41e6-97a1-f627f7cce33b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
            "0   165349.20       136897.80        471784.10    New York  192261.83\n",
            "1   162597.70       151377.59        443898.53  California  191792.06\n",
            "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
            "3   144372.41       118671.85        383199.62    New York  182901.99\n",
            "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
            "5   131876.90        99814.71        362861.36    New York  156991.12\n",
            "6   134615.46       147198.87        127716.82  California  156122.51\n",
            "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
            "8   120542.52       148718.95        311613.29    New York  152211.77\n",
            "9   123334.88       108679.17        304981.62  California  149759.96\n",
            "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
            "11  100671.96        91790.61        249744.55  California  144259.40\n",
            "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
            "13   91992.39       135495.07        252664.93  California  134307.35\n",
            "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
            "15  114523.61       122616.84        261776.23    New York  129917.04\n",
            "16   78013.11       121597.55        264346.06  California  126992.93\n",
            "17   94657.16       145077.58        282574.31    New York  125370.37\n",
            "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
            "19   86419.70       153514.11             0.00    New York  122776.86\n",
            "20   76253.86       113867.30        298664.47  California  118474.03\n",
            "21   78389.47       153773.43        299737.29    New York  111313.02\n",
            "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
            "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
            "24   77044.01        99281.34        140574.81    New York  108552.04\n",
            "25   64664.71       139553.16        137962.62  California  107404.34\n",
            "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
            "27   72107.60       127864.55        353183.81    New York  105008.31\n",
            "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
            "29   65605.48       153032.06        107138.38    New York  101004.64\n",
            "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
            "31   61136.38       152701.92         88218.23    New York   97483.56\n",
            "32   63408.86       129219.61         46085.25  California   97427.84\n",
            "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
            "34   46426.07       157693.92        210797.67  California   96712.80\n",
            "35   46014.02        85047.44        205517.64    New York   96479.51\n",
            "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
            "37   44069.95        51283.14        197029.42  California   89949.14\n",
            "38   20229.59        65947.93        185265.10    New York   81229.06\n",
            "39   38558.51        82982.09        174999.30  California   81005.76\n",
            "40   28754.33       118546.05        172795.67  California   78239.91\n",
            "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
            "42   23640.93        96189.63        148001.11  California   71498.49\n",
            "43   15505.73       127382.30         35534.17    New York   69758.98\n",
            "44   22177.74       154806.14         28334.72  California   65200.33\n",
            "45    1000.23       124153.04          1903.93    New York   64926.08\n",
            "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
            "47       0.00       135426.92             0.00  California   42559.73\n",
            "48     542.05        51743.15             0.00    New York   35673.41\n",
            "49       0.00       116983.80         45173.06  California   14681.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.Extracting Independent and dependent\n",
        "x= data_set.iloc[:, :-1].values\n",
        "y= data_set.iloc[:, 4].values\n",
        "df2=pd.DataFrame(x)\n",
        "print(\"X=\")\n",
        "print(df2.to_string())\n",
        "df3=pd.DataFrame(y)\n",
        "print(\"Y=\")\n",
        "print(df3.to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQqK9xmgcCjJ",
        "outputId": "8dbf1199-cb24-43a7-e933-8190ec54569c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X=\n",
            "            0          1          2           3\n",
            "0    165349.2   136897.8   471784.1    New York\n",
            "1    162597.7  151377.59  443898.53  California\n",
            "2   153441.51  101145.55  407934.54     Florida\n",
            "3   144372.41  118671.85  383199.62    New York\n",
            "4   142107.34   91391.77  366168.42     Florida\n",
            "5    131876.9   99814.71  362861.36    New York\n",
            "6   134615.46  147198.87  127716.82  California\n",
            "7   130298.13  145530.06  323876.68     Florida\n",
            "8   120542.52  148718.95  311613.29    New York\n",
            "9   123334.88  108679.17  304981.62  California\n",
            "10  101913.08  110594.11  229160.95     Florida\n",
            "11  100671.96   91790.61  249744.55  California\n",
            "12   93863.75  127320.38  249839.44     Florida\n",
            "13   91992.39  135495.07  252664.93  California\n",
            "14  119943.24  156547.42  256512.92     Florida\n",
            "15  114523.61  122616.84  261776.23    New York\n",
            "16   78013.11  121597.55  264346.06  California\n",
            "17   94657.16  145077.58  282574.31    New York\n",
            "18   91749.16  114175.79  294919.57     Florida\n",
            "19    86419.7  153514.11        0.0    New York\n",
            "20   76253.86   113867.3  298664.47  California\n",
            "21   78389.47  153773.43  299737.29    New York\n",
            "22   73994.56  122782.75  303319.26     Florida\n",
            "23   67532.53  105751.03  304768.73     Florida\n",
            "24   77044.01   99281.34  140574.81    New York\n",
            "25   64664.71  139553.16  137962.62  California\n",
            "26   75328.87  144135.98  134050.07     Florida\n",
            "27    72107.6  127864.55  353183.81    New York\n",
            "28   66051.52  182645.56   118148.2     Florida\n",
            "29   65605.48  153032.06  107138.38    New York\n",
            "30   61994.48  115641.28   91131.24     Florida\n",
            "31   61136.38  152701.92   88218.23    New York\n",
            "32   63408.86  129219.61   46085.25  California\n",
            "33   55493.95  103057.49  214634.81     Florida\n",
            "34   46426.07  157693.92  210797.67  California\n",
            "35   46014.02   85047.44  205517.64    New York\n",
            "36   28663.76  127056.21  201126.82     Florida\n",
            "37   44069.95   51283.14  197029.42  California\n",
            "38   20229.59   65947.93   185265.1    New York\n",
            "39   38558.51   82982.09   174999.3  California\n",
            "40   28754.33  118546.05  172795.67  California\n",
            "41   27892.92   84710.77  164470.71     Florida\n",
            "42   23640.93   96189.63  148001.11  California\n",
            "43   15505.73   127382.3   35534.17    New York\n",
            "44   22177.74  154806.14   28334.72  California\n",
            "45    1000.23  124153.04    1903.93    New York\n",
            "46    1315.46  115816.21  297114.46     Florida\n",
            "47        0.0  135426.92        0.0  California\n",
            "48     542.05   51743.15        0.0    New York\n",
            "49        0.0   116983.8   45173.06  California\n",
            "Y=\n",
            "            0\n",
            "0   192261.83\n",
            "1   191792.06\n",
            "2   191050.39\n",
            "3   182901.99\n",
            "4   166187.94\n",
            "5   156991.12\n",
            "6   156122.51\n",
            "7   155752.60\n",
            "8   152211.77\n",
            "9   149759.96\n",
            "10  146121.95\n",
            "11  144259.40\n",
            "12  141585.52\n",
            "13  134307.35\n",
            "14  132602.65\n",
            "15  129917.04\n",
            "16  126992.93\n",
            "17  125370.37\n",
            "18  124266.90\n",
            "19  122776.86\n",
            "20  118474.03\n",
            "21  111313.02\n",
            "22  110352.25\n",
            "23  108733.99\n",
            "24  108552.04\n",
            "25  107404.34\n",
            "26  105733.54\n",
            "27  105008.31\n",
            "28  103282.38\n",
            "29  101004.64\n",
            "30   99937.59\n",
            "31   97483.56\n",
            "32   97427.84\n",
            "33   96778.92\n",
            "34   96712.80\n",
            "35   96479.51\n",
            "36   90708.19\n",
            "37   89949.14\n",
            "38   81229.06\n",
            "39   81005.76\n",
            "40   78239.91\n",
            "41   77798.83\n",
            "42   71498.49\n",
            "43   69758.98\n",
            "44   65200.33\n",
            "45   64926.08\n",
            "46   49490.75\n",
            "47   42559.73\n",
            "48   35673.41\n",
            "49   14681.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.Catgorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "labelencoder_x= LabelEncoder()\n",
        "x[:, 3]= labelencoder_x.fit_transform(x[:,3])\n",
        "dt=pd.DataFrame(x)\n",
        "print(\"--------------------\")\n",
        "print(dt.to_string())\n",
        "print(\"-----------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7RQyUbHdpR8",
        "outputId": "bb59a388-924c-4cb3-b42e-12395ed04cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            "            0          1          2  3\n",
            "0    165349.2   136897.8   471784.1  2\n",
            "1    162597.7  151377.59  443898.53  0\n",
            "2   153441.51  101145.55  407934.54  1\n",
            "3   144372.41  118671.85  383199.62  2\n",
            "4   142107.34   91391.77  366168.42  1\n",
            "5    131876.9   99814.71  362861.36  2\n",
            "6   134615.46  147198.87  127716.82  0\n",
            "7   130298.13  145530.06  323876.68  1\n",
            "8   120542.52  148718.95  311613.29  2\n",
            "9   123334.88  108679.17  304981.62  0\n",
            "10  101913.08  110594.11  229160.95  1\n",
            "11  100671.96   91790.61  249744.55  0\n",
            "12   93863.75  127320.38  249839.44  1\n",
            "13   91992.39  135495.07  252664.93  0\n",
            "14  119943.24  156547.42  256512.92  1\n",
            "15  114523.61  122616.84  261776.23  2\n",
            "16   78013.11  121597.55  264346.06  0\n",
            "17   94657.16  145077.58  282574.31  2\n",
            "18   91749.16  114175.79  294919.57  1\n",
            "19    86419.7  153514.11        0.0  2\n",
            "20   76253.86   113867.3  298664.47  0\n",
            "21   78389.47  153773.43  299737.29  2\n",
            "22   73994.56  122782.75  303319.26  1\n",
            "23   67532.53  105751.03  304768.73  1\n",
            "24   77044.01   99281.34  140574.81  2\n",
            "25   64664.71  139553.16  137962.62  0\n",
            "26   75328.87  144135.98  134050.07  1\n",
            "27    72107.6  127864.55  353183.81  2\n",
            "28   66051.52  182645.56   118148.2  1\n",
            "29   65605.48  153032.06  107138.38  2\n",
            "30   61994.48  115641.28   91131.24  1\n",
            "31   61136.38  152701.92   88218.23  2\n",
            "32   63408.86  129219.61   46085.25  0\n",
            "33   55493.95  103057.49  214634.81  1\n",
            "34   46426.07  157693.92  210797.67  0\n",
            "35   46014.02   85047.44  205517.64  2\n",
            "36   28663.76  127056.21  201126.82  1\n",
            "37   44069.95   51283.14  197029.42  0\n",
            "38   20229.59   65947.93   185265.1  2\n",
            "39   38558.51   82982.09   174999.3  0\n",
            "40   28754.33  118546.05  172795.67  0\n",
            "41   27892.92   84710.77  164470.71  1\n",
            "42   23640.93   96189.63  148001.11  0\n",
            "43   15505.73   127382.3   35534.17  2\n",
            "44   22177.74  154806.14   28334.72  0\n",
            "45    1000.23  124153.04    1903.93  2\n",
            "46    1315.46  115816.21  297114.46  1\n",
            "47        0.0  135426.92        0.0  0\n",
            "48     542.05   51743.15        0.0  2\n",
            "49        0.0   116983.8   45173.06  0\n",
            "-----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.State column\n",
        "ct = ColumnTransformer([(\"State\", OneHotEncoder(), [3])], remainder =\n",
        "'passthrough')\n",
        "x = ct.fit_transform(x)\n",
        "\"\"\" We should not use all the dummy variables at the same time, so it\n",
        "must be 1 less than the total number of\n",
        "dummy variables, else it will create a dummy variable trap.\"\"\"\n",
        "print(\"----------b4 removing dummy variable-----\")\n",
        "dfx=pd.DataFrame(x)\n",
        "print(\"--------------------\")\n",
        "print(dfx.to_string())\n",
        "print(\"-----------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLBNW-yfeBib",
        "outputId": "66e4188a-e2cf-410d-ed6b-679af99037b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------b4 removing dummy variable-----\n",
            "--------------------\n",
            "      0    1    2          3          4          5\n",
            "0   0.0  0.0  1.0   165349.2   136897.8   471784.1\n",
            "1   1.0  0.0  0.0   162597.7  151377.59  443898.53\n",
            "2   0.0  1.0  0.0  153441.51  101145.55  407934.54\n",
            "3   0.0  0.0  1.0  144372.41  118671.85  383199.62\n",
            "4   0.0  1.0  0.0  142107.34   91391.77  366168.42\n",
            "5   0.0  0.0  1.0   131876.9   99814.71  362861.36\n",
            "6   1.0  0.0  0.0  134615.46  147198.87  127716.82\n",
            "7   0.0  1.0  0.0  130298.13  145530.06  323876.68\n",
            "8   0.0  0.0  1.0  120542.52  148718.95  311613.29\n",
            "9   1.0  0.0  0.0  123334.88  108679.17  304981.62\n",
            "10  0.0  1.0  0.0  101913.08  110594.11  229160.95\n",
            "11  1.0  0.0  0.0  100671.96   91790.61  249744.55\n",
            "12  0.0  1.0  0.0   93863.75  127320.38  249839.44\n",
            "13  1.0  0.0  0.0   91992.39  135495.07  252664.93\n",
            "14  0.0  1.0  0.0  119943.24  156547.42  256512.92\n",
            "15  0.0  0.0  1.0  114523.61  122616.84  261776.23\n",
            "16  1.0  0.0  0.0   78013.11  121597.55  264346.06\n",
            "17  0.0  0.0  1.0   94657.16  145077.58  282574.31\n",
            "18  0.0  1.0  0.0   91749.16  114175.79  294919.57\n",
            "19  0.0  0.0  1.0    86419.7  153514.11        0.0\n",
            "20  1.0  0.0  0.0   76253.86   113867.3  298664.47\n",
            "21  0.0  0.0  1.0   78389.47  153773.43  299737.29\n",
            "22  0.0  1.0  0.0   73994.56  122782.75  303319.26\n",
            "23  0.0  1.0  0.0   67532.53  105751.03  304768.73\n",
            "24  0.0  0.0  1.0   77044.01   99281.34  140574.81\n",
            "25  1.0  0.0  0.0   64664.71  139553.16  137962.62\n",
            "26  0.0  1.0  0.0   75328.87  144135.98  134050.07\n",
            "27  0.0  0.0  1.0    72107.6  127864.55  353183.81\n",
            "28  0.0  1.0  0.0   66051.52  182645.56   118148.2\n",
            "29  0.0  0.0  1.0   65605.48  153032.06  107138.38\n",
            "30  0.0  1.0  0.0   61994.48  115641.28   91131.24\n",
            "31  0.0  0.0  1.0   61136.38  152701.92   88218.23\n",
            "32  1.0  0.0  0.0   63408.86  129219.61   46085.25\n",
            "33  0.0  1.0  0.0   55493.95  103057.49  214634.81\n",
            "34  1.0  0.0  0.0   46426.07  157693.92  210797.67\n",
            "35  0.0  0.0  1.0   46014.02   85047.44  205517.64\n",
            "36  0.0  1.0  0.0   28663.76  127056.21  201126.82\n",
            "37  1.0  0.0  0.0   44069.95   51283.14  197029.42\n",
            "38  0.0  0.0  1.0   20229.59   65947.93   185265.1\n",
            "39  1.0  0.0  0.0   38558.51   82982.09   174999.3\n",
            "40  1.0  0.0  0.0   28754.33  118546.05  172795.67\n",
            "41  0.0  1.0  0.0   27892.92   84710.77  164470.71\n",
            "42  1.0  0.0  0.0   23640.93   96189.63  148001.11\n",
            "43  0.0  0.0  1.0   15505.73   127382.3   35534.17\n",
            "44  1.0  0.0  0.0   22177.74  154806.14   28334.72\n",
            "45  0.0  0.0  1.0    1000.23  124153.04    1903.93\n",
            "46  0.0  1.0  0.0    1315.46  115816.21  297114.46\n",
            "47  1.0  0.0  0.0        0.0  135426.92        0.0\n",
            "48  0.0  0.0  1.0     542.05   51743.15        0.0\n",
            "49  1.0  0.0  0.0        0.0   116983.8   45173.06\n",
            "-----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6.avoiding the dummy variable trap:\n",
        "x = x[:, 1:]\n",
        "df4=pd.DataFrame(x)\n",
        "print(\"Updated X=\")\n",
        "print(df4.to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R4eCgjKeRpj",
        "outputId": "816635c3-d250-4782-a093-7ce115487199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated X=\n",
            "      0    1          2          3          4\n",
            "0   0.0  1.0   165349.2   136897.8   471784.1\n",
            "1   0.0  0.0   162597.7  151377.59  443898.53\n",
            "2   1.0  0.0  153441.51  101145.55  407934.54\n",
            "3   0.0  1.0  144372.41  118671.85  383199.62\n",
            "4   1.0  0.0  142107.34   91391.77  366168.42\n",
            "5   0.0  1.0   131876.9   99814.71  362861.36\n",
            "6   0.0  0.0  134615.46  147198.87  127716.82\n",
            "7   1.0  0.0  130298.13  145530.06  323876.68\n",
            "8   0.0  1.0  120542.52  148718.95  311613.29\n",
            "9   0.0  0.0  123334.88  108679.17  304981.62\n",
            "10  1.0  0.0  101913.08  110594.11  229160.95\n",
            "11  0.0  0.0  100671.96   91790.61  249744.55\n",
            "12  1.0  0.0   93863.75  127320.38  249839.44\n",
            "13  0.0  0.0   91992.39  135495.07  252664.93\n",
            "14  1.0  0.0  119943.24  156547.42  256512.92\n",
            "15  0.0  1.0  114523.61  122616.84  261776.23\n",
            "16  0.0  0.0   78013.11  121597.55  264346.06\n",
            "17  0.0  1.0   94657.16  145077.58  282574.31\n",
            "18  1.0  0.0   91749.16  114175.79  294919.57\n",
            "19  0.0  1.0    86419.7  153514.11        0.0\n",
            "20  0.0  0.0   76253.86   113867.3  298664.47\n",
            "21  0.0  1.0   78389.47  153773.43  299737.29\n",
            "22  1.0  0.0   73994.56  122782.75  303319.26\n",
            "23  1.0  0.0   67532.53  105751.03  304768.73\n",
            "24  0.0  1.0   77044.01   99281.34  140574.81\n",
            "25  0.0  0.0   64664.71  139553.16  137962.62\n",
            "26  1.0  0.0   75328.87  144135.98  134050.07\n",
            "27  0.0  1.0    72107.6  127864.55  353183.81\n",
            "28  1.0  0.0   66051.52  182645.56   118148.2\n",
            "29  0.0  1.0   65605.48  153032.06  107138.38\n",
            "30  1.0  0.0   61994.48  115641.28   91131.24\n",
            "31  0.0  1.0   61136.38  152701.92   88218.23\n",
            "32  0.0  0.0   63408.86  129219.61   46085.25\n",
            "33  1.0  0.0   55493.95  103057.49  214634.81\n",
            "34  0.0  0.0   46426.07  157693.92  210797.67\n",
            "35  0.0  1.0   46014.02   85047.44  205517.64\n",
            "36  1.0  0.0   28663.76  127056.21  201126.82\n",
            "37  0.0  0.0   44069.95   51283.14  197029.42\n",
            "38  0.0  1.0   20229.59   65947.93   185265.1\n",
            "39  0.0  0.0   38558.51   82982.09   174999.3\n",
            "40  0.0  0.0   28754.33  118546.05  172795.67\n",
            "41  1.0  0.0   27892.92   84710.77  164470.71\n",
            "42  0.0  0.0   23640.93   96189.63  148001.11\n",
            "43  0.0  1.0   15505.73   127382.3   35534.17\n",
            "44  0.0  0.0   22177.74  154806.14   28334.72\n",
            "45  0.0  1.0    1000.23  124153.04    1903.93\n",
            "46  1.0  0.0    1315.46  115816.21  297114.46\n",
            "47  0.0  0.0        0.0  135426.92        0.0\n",
            "48  0.0  1.0     542.05   51743.15        0.0\n",
            "49  0.0  0.0        0.0   116983.8   45173.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.Splitting the dataset into training and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0)"
      ],
      "metadata": {
        "id": "14oxx8Zve1wL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8.Fitting the MLR model to the training set:\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regressor= LinearRegression()\n",
        "regressor.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "-9em7vpDfBx2",
        "outputId": "c9d8642e-0165-4d27-a62e-3ea332fb069e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9.Predicting the Test set result;\n",
        "y_pred=regressor.predict(x_test)"
      ],
      "metadata": {
        "id": "8ihWqV67firm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10.To compare the actual output values for X_test with the predicted value\n",
        "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "print(df.to_string())\n",
        "print(\"Mean\")\n",
        "print(data_set.describe())\n",
        "print(\"-------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaF0mTI4fy8y",
        "outputId": "daa79c46-264e-40af-ec53-ddd2db40f78b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Actual      Predicted\n",
            "0  103282.38  103015.201598\n",
            "1  144259.40  132582.277608\n",
            "2  146121.95  132447.738452\n",
            "3   77798.83   71976.098513\n",
            "4  191050.39  178537.482211\n",
            "5  105008.31  116161.242302\n",
            "6   81229.06   67851.692097\n",
            "7   97483.56   98791.733747\n",
            "8  110352.25  113969.435330\n",
            "9  166187.94  167921.065696\n",
            "Mean\n",
            "           R&D Spend  Administration  Marketing Spend         Profit\n",
            "count      50.000000       50.000000        50.000000      50.000000\n",
            "mean    73721.615600   121344.639600    211025.097800  112012.639200\n",
            "std     45902.256482    28017.802755    122290.310726   40306.180338\n",
            "min         0.000000    51283.140000         0.000000   14681.400000\n",
            "25%     39936.370000   103730.875000    129300.132500   90138.902500\n",
            "50%     73051.080000   122699.795000    212716.240000  107978.190000\n",
            "75%    101602.800000   144842.180000    299469.085000  139765.977500\n",
            "max    165349.200000   182645.560000    471784.100000  192261.830000\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11.Evaluating the Algorithm\n",
        "from sklearn import metrics\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnBet7jzg2jL",
        "outputId": "2ad48027-e06b-4606-bf42-939fb5c61600"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 7514.293659636814\n",
            "Mean Squared Error: 83502864.03250548\n",
            "Root Mean Squared Error: 9137.990152791011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that the value of root mean squared error is 9137.99,\n",
        "which is less than 10% of the mean value\n",
        "of the expenses in all states. This means that our algorithm is very\n",
        "accurate and good predictions."
      ],
      "metadata": {
        "id": "z_kMPC54g9Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 12.predicting the accuracy score\n",
        "from sklearn.metrics import r2_score\n",
        "score=r2_score(y_test,y_pred)\n",
        "print(\"r2 socre is \",score*100,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t70-eNgPiwQk",
        "outputId": "559739ec-090f-4fe4-9e70-89aaa7e0f073"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2 socre is  93.47068473282987 %\n"
          ]
        }
      ]
    }
  ]
}